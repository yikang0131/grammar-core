{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042a2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from src.utils import *\n",
    "from src.api import IntervenableGPTNeoXForCausalLM, IntervenableQwen2ForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494b3562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# model, tokenizer = load_model_tokenizer(\n",
    "#     model_path=\"results/qwen2-bnc/checkpoint-97790\",\n",
    "#     device_map=\"cuda\"\n",
    "# )\n",
    "\n",
    "model = IntervenableQwen2ForCausalLM.from_pretrained(\"/mnt/models/Qwen2.5-0.5B\").to(\"cuda:0\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/mnt/models/Qwen2.5-0.5B\")\n",
    "\n",
    "alignment = load_alignment(\n",
    "    alignment_path=\"svagree_das3/alignment_step_1000.pt\",\n",
    "    hidden_size=model.config.hidden_size,\n",
    "    proj_num=3,\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b85472bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 546\n",
      "Base sentence: <eos>The tables with the flower bought by the boy liked by the girl who adores another kid that was born in the city that is destroyed in the Second World War that kill Jerry\n",
      "Source sentence: <eos>The tables with the flower bought by the boy liked by the girl who adores another kid that was born in the city that is destroyed in the Second World War that kill Jerry\n",
      "Base prediction: is\n",
      "Intervened prediction: is\n",
      "Base logits - 'is': 5.787, 'are': 4.191\n",
      "Intervened logits - 'is': 5.776, 'are': 0.045\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test intervention effects\n",
    "def test_intervention_effect(base_sentence, source_sentence, interv_maps):\n",
    "    \"\"\"Test how intervening on agree_with affects the model's predictions\"\"\"\n",
    "    base_inputs = tokenizer(base_sentence, return_tensors=\"pt\").to(model.device)\n",
    "    source_inputs = tokenizer(source_sentence, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Get base prediction\n",
    "    base_output = model.intervenable_forward(**base_inputs)\n",
    "    base_logits = base_output.logits[0, -1, :]\n",
    "    \n",
    "    # Get representations\n",
    "    for interv_at, interv_id in interv_maps.items():\n",
    "        intervention_kwargs = {}\n",
    "        base_hidden = base_output.hidden_states[interv_at][0, -1, :]\n",
    "        source_hidden = model.intervenable_forward(**source_inputs).hidden_states[interv_at][0, -1, :]\n",
    "        \n",
    "        # Apply intervention on agree_with concept\n",
    "        intervened_repr = alignment(base_hidden.unsqueeze(0), source_hidden.unsqueeze(0), interv_id, top_k=200)\n",
    "        intervention_kwargs[interv_at] = intervened_repr.squeeze(0)\n",
    "        base_output = model.intervenable_forward(**base_inputs, **intervention_kwargs)\n",
    "\n",
    "    # Get intervened prediction\n",
    "    # intervened_output = model.intervenable_forward(**base_inputs, **intervention_kwargs)\n",
    "    intervened_logits = base_output.logits[0, -1, :]\n",
    "    \n",
    "    # Compare predictions for \"is\" vs \"are\"\n",
    "    is_token = tokenizer.convert_tokens_to_ids([\"is\"])[0]\n",
    "    are_token = tokenizer.convert_tokens_to_ids([\"are\"])[0]\n",
    "    print(is_token, are_token)\n",
    "\n",
    "    base_pred = \"is\" if base_logits[is_token] > base_logits[are_token] else \"are\"\n",
    "    intervened_pred = \"is\" if intervened_logits[is_token] > intervened_logits[are_token] else \"are\"\n",
    "    \n",
    "    print(f\"Base sentence: {base_sentence}\")\n",
    "    print(f\"Source sentence: {source_sentence}\")\n",
    "    print(f\"Base prediction: {base_pred}\")\n",
    "    print(f\"Intervened prediction: {intervened_pred}\")\n",
    "    print(f\"Base logits - 'is': {base_logits[is_token]:.3f}, 'are': {base_logits[are_token]:.3f}\")\n",
    "    print(f\"Intervened logits - 'is': {intervened_logits[is_token]:.3f}, 'are': {intervened_logits[are_token]:.3f}\")\n",
    "    print(\"---\")\n",
    "\n",
    "\n",
    "test_intervention_effect(\n",
    "    \"<eos>The tables with the flower bought by the boy liked by the girl who adores another kid that was born in the city that is destroyed in the Second World War that kill Jerry\",\n",
    "    \"<eos>The tables with the flower bought by the boy liked by the girl who adores another kid that was born in the city that is destroyed in the Second World War that kill Jerry\",\n",
    "    interv_maps={\n",
    "        # \"model.layers[8]\": [1],\n",
    "        \"model.layers[10]\": [2]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce977ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence00</th>\n",
       "      <th>sentence01</th>\n",
       "      <th>sentence10</th>\n",
       "      <th>sentence11</th>\n",
       "      <th>solved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;eos&gt;The author that injured the secretary</td>\n",
       "      <td>&lt;eos&gt;The author that injured the secretaries</td>\n",
       "      <td>&lt;eos&gt;The authors that injured the secretary</td>\n",
       "      <td>&lt;eos&gt;The authors that injured the secretaries</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;eos&gt;The guard that injured the secretary</td>\n",
       "      <td>&lt;eos&gt;The guard that injured the secretaries</td>\n",
       "      <td>&lt;eos&gt;The guards that injured the secretary</td>\n",
       "      <td>&lt;eos&gt;The guards that injured the secretaries</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;eos&gt;The minister that embarrassed the manager</td>\n",
       "      <td>&lt;eos&gt;The minister that embarrassed the managers</td>\n",
       "      <td>&lt;eos&gt;The ministers that embarrassed the manager</td>\n",
       "      <td>&lt;eos&gt;The ministers that embarrassed the managers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;eos&gt;The taxi driver that injured the customer</td>\n",
       "      <td>&lt;eos&gt;The taxi driver that injured the customers</td>\n",
       "      <td>&lt;eos&gt;The taxi drivers that injured the customer</td>\n",
       "      <td>&lt;eos&gt;The taxi drivers that injured the customers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;eos&gt;The executive that embarrassed the manager</td>\n",
       "      <td>&lt;eos&gt;The executive that embarrassed the managers</td>\n",
       "      <td>&lt;eos&gt;The executives that embarrassed the manager</td>\n",
       "      <td>&lt;eos&gt;The executives that embarrassed the managers</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentence00  \\\n",
       "0       <eos>The author that injured the secretary   \n",
       "1        <eos>The guard that injured the secretary   \n",
       "2   <eos>The minister that embarrassed the manager   \n",
       "3   <eos>The taxi driver that injured the customer   \n",
       "4  <eos>The executive that embarrassed the manager   \n",
       "\n",
       "                                         sentence01  \\\n",
       "0      <eos>The author that injured the secretaries   \n",
       "1       <eos>The guard that injured the secretaries   \n",
       "2   <eos>The minister that embarrassed the managers   \n",
       "3   <eos>The taxi driver that injured the customers   \n",
       "4  <eos>The executive that embarrassed the managers   \n",
       "\n",
       "                                         sentence10  \\\n",
       "0       <eos>The authors that injured the secretary   \n",
       "1        <eos>The guards that injured the secretary   \n",
       "2   <eos>The ministers that embarrassed the manager   \n",
       "3   <eos>The taxi drivers that injured the customer   \n",
       "4  <eos>The executives that embarrassed the manager   \n",
       "\n",
       "                                          sentence11  solved  \n",
       "0      <eos>The authors that injured the secretaries    True  \n",
       "1       <eos>The guards that injured the secretaries    True  \n",
       "2   <eos>The ministers that embarrassed the managers    True  \n",
       "3   <eos>The taxi drivers that injured the customers    True  \n",
       "4  <eos>The executives that embarrassed the managers    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "solved = pd.read_json(\"data/svagree/solved.train.jsonl\", lines=True)\n",
    "unsolved = pd.read_json(\"data/svagree/unsolved.train.jsonl\", lines=True)\n",
    "data = pd.concat([solved, unsolved], ignore_index=True)\n",
    "\n",
    "concept_config = { 0: \"model.layers[4]\", 1: \"model.layers[4]\", 2: \"model.layers[5]\" }\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2fe960d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [00:11<00:00, 63.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "target_reprs = {\n",
    "    \"number\": [],\n",
    "    \"representation\": [],\n",
    "}\n",
    "\n",
    "distractor_reprs = {\n",
    "    \"number\": [],\n",
    "    \"representation\": [],\n",
    "}\n",
    "\n",
    "agree_reprs = {\n",
    "    \"representation\": [],\n",
    "}\n",
    "\n",
    "solved = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, row in tqdm(data.iterrows(), total=len(data)):\n",
    "        for k in [\"sentence00\", \"sentence01\", \"sentence10\", \"sentence11\"]:\n",
    "            sentence = row[k]\n",
    "            concept_reps = get_concept_representations(\n",
    "                sentence,\n",
    "                tokenizer,\n",
    "                model,\n",
    "                alignment,\n",
    "                200,\n",
    "                concept_config\n",
    "            )\n",
    "            target_num, distractor_num = k[-2:]\n",
    "            target_reprs[\"number\"].append(int(target_num))\n",
    "            distractor_reprs[\"number\"].append(int(distractor_num))\n",
    "            target_reprs[\"representation\"].append(concept_reps[0].cpu().numpy())\n",
    "            distractor_reprs[\"representation\"].append(concept_reps[1].cpu().numpy())\n",
    "            agree_reprs[\"representation\"].append(concept_reps[2].cpu().numpy())\n",
    "            solved.append(1 if row.solved else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06dfc961",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = pd.DataFrame(target_reprs)\n",
    "distractor_df = pd.DataFrame(distractor_reprs)\n",
    "agree_df = pd.DataFrame(agree_reprs)\n",
    "solved = pd.Series(solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3399058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne(representations, labels, title):\n",
    "    from sklearn.manifold import TSNE\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    repr_matrix = np.stack(representations)\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(repr_matrix)\n",
    "\n",
    "    # Map labels to colors\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.get_cmap('tab10', len(unique_labels))\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for idx, label in enumerate(unique_labels):\n",
    "        mask = np.array(labels) == label\n",
    "        plt.scatter(tsne_results[mask, 0], tsne_results[mask, 1], \n",
    "                    alpha=0.6, label=str(label), color=colors(idx))\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"TSNE Dimension 1\")\n",
    "    plt.ylabel(\"TSNE Dimension 2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17167569",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_tsne() missing 1 required positional argument: 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# data = target_df[solved == 0]\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m agree_df\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplot_tsne\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrepresentation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# data[\"number\"],\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# solved,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSolved Target Representations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_tsne() missing 1 required positional argument: 'labels'"
     ]
    }
   ],
   "source": [
    "# data = target_df[solved == 0]\n",
    "data = agree_df\n",
    "\n",
    "plot_tsne(\n",
    "    data[\"representation\"],\n",
    "    # data[\"number\"],\n",
    "    solved,\n",
    "    title=\"Solved Target Representations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fe75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
